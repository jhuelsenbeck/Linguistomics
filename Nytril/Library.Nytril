using Format, Units, Math, IO, Rev;
//======================================================================

class LanguageClass {
  var Name,
      Cases,
      Variable,
      MapImage,
      MapAttribution;

  Constructor(name, cases=0) {
    Name  = name;
    Cases = cases;
  }

  virtual Description = null;
  virtual Details = null;

  override GetLayout = Span {
    Popup: this;
    Name;
  };

  override GetPopup = Block {
    Paragraph {
      Bold;
      TextHeight: 14 pts;
      Name;
    };
    Description {
      RightIndent: 3.5 inches;
    };
    ShowMap(Size(5 inches, 3 inches));
  };

  LoadImage(name) = IO.Read(Info.ImageFolder FileName(name));

  ShowMap(size) {
    if (valid MapImage) {
      return VBox {
        var h = 6 pts;

        HAlign: HAligns.Center;

        MapImage {
          Size: Size(size.Width, size.Height - h);
          Proportional: true;
        };

        Span {
          TextHeight: h;
          TextColor: 80%;
          Lang.Credit;
          Popup: MapAttribution;
        }
      };
    }
    return null;
  }
}
//======================================================================

class CognateClass {
  var Name,
      Title,
      Words,
      Concept,
      Cognate,
      MaxLength;

  Constructor(concept, cognate) {
    Name = concept.GlobalVariableName;
    var n = cognate.GlobalVariableName;
    if (n[..6] == "Primary")
      Title = Name;
    else
      Title = Name + '-' + n;
    Concept    = concept;
    Cognate    = cognate;
    MaxLength  = 0;
  }
}
//======================================================================

class WordClass {
  var Language,
      Cognate,
      Text,
      Segments,
      Aligned,
      Padded;

  Constructor(language, cognate, text) {
    Language = language;
    Cognate  = cognate;
    Text     = text;
    if (text.Length > 0) {
      var segments = IPA.SegmentDictionary.FindTokens(text, IPA.NoSegment);
      Aligned  = Math.FindSlice(segments, s => s.Gap or (not s.Punctuation));
      Segments = Math.FindSlice(segments, s => not s.Punctuation);

      // Test that the word's text is the same as the segments converted back into text
      var view = String(Span {(each segments).Ipa});
      System.Assert(text == view, "Round-trip error with text {0}-{1}"(text, view), text);
    }
    else {
      Segments = [];
      Aligned  = [];
    }
  }

  ShowConcept = Span {
    Style.SansSerif;
    Popup: this;
    Cognate.Title;
  };

  override GetLayout = Span {
    foreach (var s in Segments) {
      if (!s.Punctuation)
        s.Ipa;
    }
  };

  override GetPopup = Frame {
    AllWords.ShowConceptTable(Cognate);
  };
}
//======================================================================

class TaxonClass {
  var Variable,
      Language,
      Index;

  Constructor(lang) {
    Index    = EachIndex;
    Language = lang;
    Variable = lang.GlobalVariableName;
  }

  override GetLayout = Span {
    TaxonFormat;
    Variable;
    Popup: Language;
  };
}
//======================================================================

enum Models {
  JC,
  MK,
}

class ResultsClass {
  var CharacterRule,
      PartitionRule,
      UsedCognates,
      Taxa,
      DisplaySegments,
      UniqueSegments,
      UniqueCharacters,
      TotalLength,
      OutFolder,
      EXEName,
      RevSourceName,
      GammaTrees,
      GammaLog,
      GammaMAP,
      GammaMCC,
      GammaConsensus,
      CharacterName,
      WordCount,
      Frequencies,
      Rates,
      AddComma,
      Model;


  Constructor(folder) {
    WordCount      = 0;
    Model          = Models.JC;
    OutFolder      = Folders.Repository Folder("Run") Folder(folder);
    EXEName        = Folders.Repository Folder("RevBayes") FileName("rb") Extensions.EXE;
    RevSourceName  = FileName("Program") Extensions.RevBayes;
    CharacterName  = FileName("Characters") Extensions.Nexus;
    GammaTrees     = FileName("Gamma.trees");
    GammaLog       = FileName("Gamma.log");
    GammaMAP       = FileName("Gamma_MAP") Extensions.Tree;
    GammaMCC       = FileName("Gamma_MCC") Extensions.Tree;
    GammaConsensus = FileName("Gamma_Consensus") Extensions.Tree;


    Frequencies = [0.2, 0.2, 0.3, 0.4, 1.0];
    Rates = [
      [1, 2, 3, 4, 10],
      [0, 2, 3, 4, 5],
      [0, 0, 3, 4, 5],
      [0, 0, 0, 4, 5],
      [0, 0, 0, 0, 20],
    ];

    GetConcepts;
    foreach (var cognate in UsedCognates)
      ComputeCognate(cognate);

    // Here we assign a character letter to each unique segment from a set of possible Nexus file characters
    CharacterRule = new SingletonRuleClass;
    PartitionRule = new Partition1Class;

//    Rule = new DiphthongRuleClass;
//    Rule = new VowelsSeparatedRuleClass;
//    Rule = new SegmentTypesRuleClass;

    GetUniqueSegments;
    CharacterRule.AssignCharacters(UniqueSegments);
    PartitionRule.AssignPartitions(UniqueSegments);

    var max = 0;
    foreach (var segment in UniqueSegments) {
      if (segment.CharacterIndex > max)
        max = segment.CharacterIndex;
    }
    UniqueCharacters = max+1;
  }

  void GetUniqueSegments {
    var set = new DictionaryClass(256);
    foreach (var cognate in UsedCognates) {
      foreach (var word in cognate.Words) {
        foreach (var segment in word.Segments) {
          if (!segment.Punctuation)
            set.Add(segment, segment.Ipa);
        }
      }
    }
    UniqueSegments  = set.Values;
    DisplaySegments = UniqueSegments;  // Could be IPA.Segments if you want to see all possible segments in the debug tables
    GetFrequencies;
  }

  void GetFrequencies {
    var set = new DictionaryClass(1024);
    foreach (var sd in SegmentFrequencyData)
      set.Add(sd, sd.Text);

    var sum = 0.0;
    foreach (var s in UniqueSegments) {
      if (not s.Punctuation) {
        var f = set.FindKey(s.Ipa);
        if (valid f)
          s.Frequency = f.Frequency;
        sum += s.Frequency;
      }
    }
    if (sum > 0) {
      sum = 1.0 / sum;

      foreach (var s in UniqueSegments) {
        s.NormalFrequency  = s.Frequency * sum;
        s.FrequencyPercent = s.NormalFrequency*100.0;
      }
    }
  }

  void GetConcepts {
    var set = new DictionaryClass(256);

    TotalLength = 0;
    var clist = new ListClass(256);
    foreach (var concept in Concepts) {
      if (exists concept.?Done) {
        foreach (var cognate in concept) {
          var vname = cognate.GlobalVariableName();
          if (vname != "Done" and vname != "Verb") {
            var count = 0;
            foreach (var t in cognate) {
              var tn = t.GlobalVariableName();
              set.Add(tn, tn);
              if (t.Length > 0)
                ++count;
            }
            if (count > 1) {
              WordCount += count;
              clist.Add(new CognateClass(concept, cognate));
            }
          }
        }
      }
    }
    UsedCognates = clist.ToArray;

    var nameset = set.Values;
    var tlist   = new ListClass(nameset.Length);

    foreach (var ln in nameset) {
      var lang = Languages.GetField(ln);
      if (valid lang)
        tlist.Add(new TaxonClass(lang));
      else
        System.Assert("Invalid language", lang);
    }
    Taxa = tlist.ToArray;
  }

  ShowLanguageDetails = Block {
    foreach (var taxon in Taxa) {
      var language = taxon.Language;
      Style.Header2 {
        language.Name;
      };
      Block {
        Paragraph {
          ParAlignment: ParAlignments.Center;
          if (valid language.MapImage)
            language.ShowMap(Size(5 inches, 3 inches));
        };
        language.Description;
        language.Details;
      }
    }
  };

  void ComputeCognate(cognate) {
    var words     = new ListClass(Taxa.Length);
    var maxlength = 0;

    foreach (var taxon in Taxa) {
      var word = null;
      foreach (var langword in cognate.Cognate) {
        if (langword.GlobalVariableName == taxon.Variable) {
          word      = new WordClass(taxon.Language, cognate, langword);
          maxlength = Math.Max([maxlength, word.Aligned.Length]);
          break;
        }
      }
      if (word == null)
        word = new WordClass(taxon.Language, cognate, Empty);
      words.Add(word);
    }

    cognate.Words     = words.ToArray;
    cognate.MaxLength = maxlength;
    foreach (var word in cognate.Words) {
      var a = word.Aligned;
      if (a.Length > 0) {
        if (a.Length < maxlength)
          word.Padded = a + [IPA.Segments.GapSegment] * (maxlength - a.Length);
        else
          word.Padded = a;
      }
      else
        word.Padded = a;
    }

    for (var i = 0; i < maxlength; ++i) {
      var count    = 0;
      var gapcount = 0;
      foreach (var word in cognate.Words) {
        if (valid word.Aligned) {
          ++count;
          if (word.Padded[i] == IPA.Segments.GapSegment)
            ++gapcount;
        }
      }
      System.Assert(gapcount < count, "Column with all gaps", cognate.Cognate);
    }

    TotalLength += maxlength;
  }

  ShowLanguages = Block {
    var rows      = 2;
    var cols      = (Taxa.Length + 1) div rows;
    var taxagroup = Taxa / cols;
    var h         = 14 pts;
    var space     = 5 pts;
    var size      = Size(DocMetrics.SlideContent.Width / cols - space, DocMetrics.SlideContent.Height / rows - space);

    foreach (var group in taxagroup) {
      HBox {
        PaddingT: space;
        VAlign: VAligns.Top;

        foreach (var taxon in group) {
          VBox {
            MarginR: space;
            Size: size;
            HAlign: HAligns.Center;

            Paragraph {
              TextHeight: h;
              Bold;
              taxon.Language;
            };

            HBox {
              VAlign: VAligns.Center;

              var s = Size(size.Width, size.Height - h);
              Size: s;
              Corner: 20 pts;
              BorderStroke: 1 pts {Color: 90%};
              BorderClip: true;

              Span {
                Popup: taxon.Language;
                taxon.Language.ShowMap(s);
              }
            };
          }
        }
      }
    }
  };

  void Calculate {
    CreateFolder(OutFolder);
    if (not CharacterRule.Numbers) {
      IO.Write(CharacterFile(1), OutFolder CharacterName);
      IO.Write(RevBayesSource, OutFolder RevSourceName);
    }
    IO.Write(RunBatchFile, OutFolder FileName("Run") Extension("bat"), FileFormats.ANSI);
    IO.Write(ConfigFile, OutFolder FileName("config") Extensions.JSON, FileFormats.Text);


    var p = new RevProcessClass(EXEName, OutFolder RevSourceName) {
/*      CacheName: "RevBayes";
      CacheInput: [
        OutFolder CharacterName,
        OutFolder RevSourceName,
      ];
      CacheOutput: [
        OutFolder GammaTrees,
        OutFolder GammaConsensus,
        OutFolder GammaMAP,
        OutFolder GammaMCC,
        OutFolder GammaLog,
      ];
*/
      Directory: OutFolder;
    };

//    var results = p.Run;
//    if (results.ExitCode != 0)
//      System.Assert(false, results.StandardOutput, p);
  }

  ShowLanguageTrees = Block {
    Style.ShowTree("Commonly Accepted Romance Tree", Lang.Years, GetTreeNodes(LanguageBranches.Romance));
    Style.ShowTree("Priors", Lang.Years, GetTreeNodes(LanguageBranches.Experiment));
    ReadTree("Consensus", OutFolder GammaConsensus);
    ReadTree("MAP", OutFolder GammaMAP);
    ReadTree(Lang.MCC, OutFolder GammaMCC);
  };

  ShowStats = Block {
    var schema = new LogSchemaClass();
    var view   = schema.ReadTextFile(OutFolder GammaLog, true, DB.ValueTypes.Double);
    schema.GetHistogram(view, "alpha");

    schema.LineChart(view, "Prior");
    schema.LineChart(view, "Likelihood");
    schema.LineChart(view, "Posterior");
    schema.LineChart(view, "Tree Length", "TL");

//    schema.LineChart(view, null, each "bl[{0}]"(each 1..Concepts*2));
//    schema.LineChart(view, null, each "site_rates[{0}]"(each 1..Concepts));
  };

  RunBatchFile = TextBlock {
    Span {
      "\"../../revbayes/rb.exe\" \"";
      OutFolder RevSourceName;
      "\"";
    }
  };

  CompareSegments(d1, d2) = d1.NormalFrequency.Compare(d2.NormalFrequency);

  FrequencyChart(SizeClass size) = Chart {
    var sorted = Math.Sort(UniqueSegments, true, ref CompareSegments);
    Style.SansSerif;
    Size: size;
    Type: ChartTypes.Column;
    ValueLabel: "Frequency %" {
      Transform: Rotate(90 degrees);
      TransformFit: true;
    };
    XAxis: ChartAxis {
      TextHeight: 0.6 * size.Width / sorted.Length;
      (each sorted).ShowSegment;
    };
    ValueAxis: ChartAxis;
    ChartSeries {
      (each sorted).FrequencyPercent;
    }
  };

  AddTree = TextBlock {
    Span {
      Variable("Tree");
      Quote;
      Newick(GetTreeNodes(LanguageBranches.Experiment));
      ";"; Quote; ",";
    };
  };

  AddScope = TextBlock {
    IndentSpace: 2;
    Begin: "{";
    End: "}";
  };

  AddWord(word, last) = Span {
    "  {";
    Variable("Taxon");
    ShowString(word.Language.GlobalVariableName);
    CommaSpace;
    Variable("Segments");
    "[";
    Span {
      Separator: CommaSpace;
      (each word.Padded).CharacterIndex;
    };
    Span {
      "]}";
      if (not last)
         ",";
    };
  };

  AddCognate(cognate, last) = TextBlock {
    Span {
      "{";
      Variable("Name");
      ShowString(cognate.Title);
      CommaSpace;
      Variable("Data"); "[";
    };

    TextBlock {
      var good = FindSlice(cognate.Words, w => valid w.Aligned);
      var lg   = good.Length-1;
      foreach (var word in good)
        AddWord(word, EachIndex == lg);
    };

    Span {
      "]}";
      if (not last)
        ",";
    };
  };

  ConfigFile = AddScope {
    Style.MonoFamily;
    TextHeight: 9 pts;

    AddTree;
    Span {
      Variable("NumberOfStates");
      UniqueCharacters;
      CommaSpace;
    };

    ArraySpan("Taxa") {
      Separator: CommaSpace;
      ShowString(each (each Taxa).Variable);
    };

    ArraySpan("PriorFrequencies") {
      Span {
        TextDigits: 6;
        Separator: ",";
        (each UniqueSegments).NormalFrequency;
      };
    };

    ArraySpan("PartitionSets") {
      Span {
        Separator: ",";
        foreach (var partition in PartitionRule.Partitions) {
          Span {
            "{";
            Variable("Name");
            ShowString(partition.Filter.Name);
            CommaSpace;
            Variable("Set");
            "[";
            Span {
              Separator: CommaSpace;
              (each partition.Segments).CharacterIndex;
            };
            "]}";
          }
        }
      };
    };

    Span {
      Variable("Words"); "[";
    };
    TextBlock {
      var last = UsedCognates.Length-1;
      foreach (var cognate in UsedCognates)
        AddCognate(cognate, EachIndex == last);
    };
    "]";
  };

  RevBayesSource = TextBlock {
    Style.MonoFamily;
    BlockComment("RevBayes Source File for Linguistomics Project");

    "clear()";
//    "setwd({0})"(ShowString(folder));
    "path = " ShowString(OutFolder Folder("/"));
    "gammapath = {0}"(PathPlus(GammaTrees));


    LineComment("Read in discrete character data");
    "data = readDiscreteCharacterData({0})"(PathPlus(CharacterName));

    LineComment("Get some useful variables from the data. We need these later on");
    "num_taxa <- data.ntaxa()";

    LineComment("Number of branches in an rooted tree");
    "num_branches <- 2 * num_taxa - 2";

    "taxa <- data.taxa()";

    LineComment("Create helper variables");
    "moves    = VectorMoves()";
    "monitors = VectorMonitors()";

    BlockComment("Tree Model");
    LineComment("Outgroup is a clade consisting of one language");
    "out_group = clade({0})"(ShowString(Languages.Latin));

    LineComment("Prior distribution on the tree topology");
    "topology ~ dnUniformTopology(taxa, outgroup=out_group, rooted=TRUE)";

    LineComment("These are moves that change the tree topology");
    "moves.append(mvNNI(topology, weight=num_taxa/2.0))";
    "moves.append(mvSPR(topology, weight=num_taxa/10.0))";

    LineComment("Branch length prior");

    "for (i in 1:num_branches) {";
    "  bl[i] ~ dnExponential(10.0)";
    "  moves.append(mvScale(bl[i]))";
    "}";
    Empty;
    "TL  := sum(bl)";
    Empty;
    "psi := treeAssembly(topology, bl)";
    Empty;

    BlockComment("Substitution Model");
    LineComment("This is the number of unique characters from the segment filters");
    "unique_chars = {0}"(UniqueCharacters);

    switch (Model) {
      case Models.JC:
        LineComment("Jukes-Cantor model");
        "Q <- fnJC(unique_chars)";
        break;

      case Models.MK:
        LineComment("Mk model");
        LineComment("I'm guessing completely with this number");
        "rate_pr <- 10.0";
        Empty;
        "rate_parameter ~ dnExponential(rate_pr)";
        Empty;
        Empty;
        "moves.append(mvScale(rate_parameter, weight=2))";
        Empty;
        "for (i in 1:unique_chars) {";
        "  for (j in 1:unique_chars) {";
        "    m[i][j] := rate_parameter";
        "  }";
        "}";
        Empty;
        "Q := fnFreeK(m, rescale=TRUE)";
        break;
    }

    BlockComment("Gamma model for among-site variation");

    "alpha ~ dnUniform(0, 10.0)";
    "moves.append(mvScale(alpha, weight=1))";

    "site_rates := fnDiscretizeGamma(alpha, alpha, 4)";

    BlockComment("PhyloCTMC Model");
    "seq ~ dnPhyloCTMC(tree=psi, Q=Q, type={0}, siteRates=site_rates)"(ShowString("Standard"));
    "seq.clamp(data)";

    BlockComment("Analysis");

    LineComment("You can use any node as the argument of model()");
    "mymodel = model(psi)";
    "n_gen   = {0}"(Math.Min([100, Math.Max([10, Info.Generations div 1000])]));

    LineComment("This prints monitors to the screen");
    Span {
      "monitors.append(mnScreen(TL, ";
      if (Model == Models.MK)
        "rate_parameter, ";
      "printgen=n_gen))";
    };

    LineComment("This monitors the trees and puts them in a file");
    "monitors.append(mnFile(psi, filename=gammapath, printgen=n_gen))";

    LineComment("Model monitor");
    "monitors.append(mnModel(filename={0}, printgen=n_gen))"(PathPlus(GammaLog));

    "mymcmc = mcmc(mymodel, moves, monitors, nruns=1, combine={0})"(ShowString("mixed"));


//   "mymcmc.burnin(generations={0}, tuningInterval=200)"(Info.Generations);
    "mymcmc.run(generations={0})"(Info.Generations);

    LineComment("Summarizes the MCMC runs");
    "mymcmc.operatorSummary()";

    BlockComment("Post processing");
    "treetrace      = readTreeTrace(gammapath, outgroup=out_group)";
    "map_tree       = mapTree(treetrace, {0})"(PathPlus(GammaMAP));
    "mcc_tree       = mccTree(treetrace, {0})"(PathPlus(GammaMCC));
    "consensus_tree = consensusTree(treetrace, {0})"(PathPlus(GammaConsensus));

    LineComment("Exit the program");
    "q()";
  };

  CharacterFile(paper) = NexusFile {
    var maxlength = MaxNameLength;
    var ntax      = Taxa.Length;

    TabStops: [4 inches];

    Scope("taxa") {
      AddLine("dimensions") {
        AddValue("ntax", ntax);
      };
      AddLine("taxlabels") {
        AddTaxon(each Taxa);
      };
    };

    Scope("characters") {
      AddLine("dimensions") {
        AddValue("ntax", ntax);
        AddValue("nchar", TotalLength);
      };
      AddLine("format") {
        AddValue("datatype", "STANDARD");
        AddValue("interleave", "yes");
        AddValue("respectcase");
        AddValue("gap", IPA.Segments.GapSegment.Ipa);
        AddValue("missing", IPA.Segments.MissingSegment.Ipa);
        AddValue("symbols", Span {Quote; CharacterList[0..<Math.Min([UniqueCharacters, Rev.CharacterList.Length])]; Quote});
      };

      Empty;
      Keyword("matrix");

      foreach (var cognate in UsedCognates) {
        if (EachIndex > 0)
          Empty;

        Comment(cognate.Name);
        WriteTaxa(cognate, paper, maxlength);
      }
      EndMarker;
    };
  };

  MaxNameLength = Math.Max((each ((each Taxa).Variable)).Length) + 1;

  WriteTaxa(cognate, paper, maxlength) = TextBlock {
    foreach (var taxon in Taxa) {
      var words = cognate.Words[taxon.Index];
      Span {
        taxon.Variable;
        Space * (maxlength - taxon.Variable.Length);
        foreach (var segment in words.Padded)
          segment.ShowCharacter;

        switch (paper) {
          case 0:
            break;

          case 1:
            break;

          case 2:
            Span {
              CommentFormat;
              Style.IPAFamily;
              Tab;
              foreach (var segment in words.Padded)
                segment.ShowBlock;
            };
            break;
        }
      };
    }
  };
}
//======================================================================

