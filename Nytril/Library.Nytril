using Format, Units, Math, IO, Rev;
//======================================================================

class LanguageClass {
  var Name,
      Cases,
      Variable,
      MapImage,
      MapAttribution;

  Constructor(name, cases=0) {
    Name  = name;
    Cases = cases;
  }

  virtual Description = null;
  virtual Details = null;

  override GetLayout = Span {
    Popup: this;
    Name;
  };

  override GetPopup = Block {
    Paragraph {
      Bold;
      TextHeight: 14 pts;
      Name;
    };
    if (valid Description) {
      Description {
        RightIndent: 3.5 inches;
      };
    }
    ShowMap(Size(5 inches, 3 inches));
  };

  LoadImage(name) = IO.Read(Info.ImageFolder FileName(name));

  ShowMap(size) {
    if (valid MapImage) {
      return VBox {
        var h = 6 pts;

        HAlign: HAligns.Center;

        MapImage {
          Size: Size(size.Width, size.Height - h);
          Proportional: true;
        };

        Span {
          TextHeight: h;
          TextColor: 80%;
          Lang.Credit;
          Popup: MapAttribution;
        }
      };
    }
    return null;
  }
}
//======================================================================

class WordClass {
  LanguageClass  Language;
  CognateClass   Cognate;
  SegmentClass[] Segments,
                 Aligned,
                 Padded;
  var            Text,
                 Plain;

  Constructor(dictionary, LanguageClass language, CognateClass cognate, text) {
    // IPA text and word text must be in the same unicode normaization form so comparisons are accurate
    Text     = text.GetString(NormalizationForms.FormC);
    Plain    = Text.FindSlice(c => c != IPA.Segments.GapSegment.Ipa and c != IPA.Segments.PrimaryStress.Ipa);
    Language = language;
    Cognate  = cognate;
    if (Text.Length > 0) {
      var segments = dictionary.FindTokens(Text, IPA.NoSegment);
      Aligned  = segments.FindSlice(s => s.Gap or (not s.Punctuation));
      Segments = segments.FindSlice(s => not s.Punctuation);

      // Test that the word's text is the same as the segments converted back into text
      var view = Span {(each segments).Ipa};
      System.Assert(Text == view.GetString(), "Round-trip error with text {0}-{1}"(Text, view), Text);
    }
    else {
      Segments = [];
      Aligned  = [];
    }
  }

  ShowConcept = Span {
    Style.SansSerif;
    Popup: this;
    Cognate.Title;
  };

  override GetLayout = Span {
    foreach (var s in Segments) {
      if (!s.Punctuation)
        s.Ipa;
    }
  };

  ShowPaddedBlocks(w) = Table {
    Columns: [w]*Padded.Length;
    Row {
      foreach (var segment in Padded) {
        Cell {
          EdgeL: (0.125 pts) {Color: 80%};
          ParAlignment: ParAlignments.Center;
          segment.ShowSegment;
        };
      }
    };
  };

  FieldPar(name) = Paragraph {
    TabStops: [0.5 inches];
    Bold name;
    Tab;
  };

  override GetPopup = Block {
    FieldPar(Lang.Language) {
      Language;
    };
    FieldPar(Lang.Concept) {
      Cognate.Title;
    };
    FieldPar(Lang.Segments) {
      Frame {
        Border: 0.5;
        TextHeight: 16 pts;
        ShowPaddedBlocks(20 pts);
      }
    }
  };
}
//======================================================================

class CognateClass {
  WordClass[] Words;
  var         Name,
              Title,
              MaxLength,
              Concept,
              Cognate;

  Constructor(concept, cognate) {
    Name = concept.GlobalVariableName;
    var n = cognate.GlobalVariableName;
    if (n[..6] == "Primary")
      Title = Name;
    else
      Title = Name + '-' + n;
    Concept   = concept;
    Cognate   = cognate;
    MaxLength = 0;
  }

  override GetPopup = AllWords.ShowConceptTable(this);
}
//======================================================================

class TaxonClass {
  var           Variable,
                Index;
  LanguageClass Language;

  Constructor(LanguageClass language) {
    Index    = EachIndex;
    Language = language;
    Variable = language.GlobalVariableName;
  }

  override GetLayout = Span {
    TaxonFormat;
    Variable;
    Popup: Language;
  };
}
//======================================================================

enum Models {
  JC,
  MK,
}

class ResultsClass {
  RuleClass       CharacterRule,
                  PartitionRule;
  TransitionClass TransitionExperiment,
                  TransitionStatic;
  SegmentClass[]  UniqueSegments,
                  SortedSegments;
  CognateClass[]  UsedCognates;
  MatrixClass     TransitionCount;
  TaxonClass[]    Taxa;
  var             DisplaySegments,
                  UniqueCharacters,
                  ConceptCount,
                  TotalLength,
                  OutFolder,
                  EXEName,
                  RevSourceName,
                  GammaTrees,
                  GammaLog,
                  GammaMAP,
                  ConsensusTree,
                  GammaConsensus,
                  CharacterName,
                  WordCount,
                  SegmentCount,
                  AddComma,
                  Model;

  Constructor(folder) {
    WordCount      = 0;
    SegmentCount   = 0;
    Model          = Models.JC;
    OutFolder      = Folders.Repository Folder("Run") Folder(folder);
    EXEName        = Folders.Repository Folder("RevBayes") FileName("rb") Extensions.EXE;
    RevSourceName  = FileName("Program") Extensions.RevBayes;
    CharacterName  = FileName("Characters") Extensions.Nexus;
    GammaTrees     = FileName("Gamma.trees");
    GammaLog       = FileName("Gamma.log");
    GammaMAP       = FileName("Gamma_MAP.tree");
    ConsensusTree  = FileName("test.con.tre");
    GammaConsensus = FileName("Gamma_Consensus.tree");

    // Here we assign a character letter to each unique segment from a set of possible Nexus file characters
    CharacterRule        = new SingletonRuleClass;
    PartitionRule        = new Partition2Class;
    TransitionExperiment = new TransitionClass(PartitionRule);
    TransitionStatic     = new TransitionClass(PartitionRule);
  }

  void Calculate {
    // Build a dictionary with IPA text as the key
    var dictionary = new DictionaryClass(256, SegmentClass);
    foreach (var segment in IPA.Segments) {
      if (segment.Ipa.Length > 0)
        dictionary.Add(segment, segment.Ipa);
    }
    InitConcepts;

    foreach (var cognate in UsedCognates)
      ComputeCognate(dictionary, cognate);

    UniqueSegments  = GetUniqueSegments;
    DisplaySegments = UniqueSegments;  // Could be IPA.Segments if you want to see all possible segments in the debug tables
    SortedSegments  = UniqueSegments.Sort(true, ref AlphaOrder);

    var max = 0;
    foreach (var segment in UniqueSegments) {
      segment.Index = EachIndex;
      if (segment.CharacterIndex > max)
        max = segment.CharacterIndex;
    }
    UniqueCharacters = max+1;

    GetFrequencies;
    TransitionExperiment.ReadFrequencies;
    TransitionStatic.StaticFrequencies;
    CharacterRule.AssignCharacters;
    PartitionRule.AssignPartitions;
  }

  SegmentClass[] GetUniqueSegments {
    var set = new HashSetClass(512, SegmentClass);
    foreach (var cognate in UsedCognates) {
      foreach (var word in cognate.Words) {
        foreach (var segment in word.Segments) {
          if (!segment.Punctuation)
            set.Add(segment);
        }
      }
    }
    return set.Values;
  }

  void InitConcepts {
    var set = new DictionaryClass(256);

    TotalLength  = 0;
    ConceptCount = 0;

    var clist = new ListClass(256);
    foreach (var concept in Concepts) {
      if (exists concept.?Done) {
        ++ConceptCount;
        foreach (var cognate in concept) {
          var vname = cognate.GlobalVariableName();
          if (vname != "Done" and vname != "Verb") {
            var count = 0;
            foreach (var t in cognate) {
              var tn = t.GlobalVariableName;
              set.Add(tn, tn);
              if (t.Length > 0)
                ++count;
            }
            if (count > 1) {
              WordCount += count;
              clist.Add(new CognateClass(concept, cognate));
            }
          }
        }
      }
    }
    UsedCognates = clist.Values;

    var nameset = set.Values;
    var tlist   = new ListClass(nameset.Length);

    foreach (var ln in nameset) {
      var language = Languages.GetField(ln);
      if (valid language)
        tlist.Add(new TaxonClass(language));
      else
        System.Assert(false, "Invalid language", language);
    }
    Taxa = tlist.Values;
  }

  void ComputeCognate(DictionaryClass dictionary, CognateClass cognate) {
    var words     = new ListClass(Taxa.Length);
    var maxlength = 0;

    foreach (var taxon in Taxa) {
      var word = null;
      foreach (var langword in cognate.Cognate) {
        if (langword.GlobalVariableName == taxon.Variable) {
          var w     = new WordClass(dictionary, taxon.Language, cognate, langword);
          maxlength = Math.Max([maxlength, w.Aligned.Length]);

          foreach (var s in w.Segments) {
            ++SegmentCount;
            ++s.UsedCount;
          }

          word = w;
          break;
        }
      }
      words.Add(word ?? new WordClass(dictionary, taxon.Language, cognate, Empty));
    }

    cognate.Words     = words.Values;
    cognate.MaxLength = maxlength;
    foreach (var word in cognate.Words) {
      var a = word.Aligned;
      if (a.Length > 0) {
        if (a.Length < maxlength)
          word.Padded = a + [IPA.Segments.GapSegment] * (maxlength - a.Length);
        else
          word.Padded = a;
      }
      else
        word.Padded = a;
    }

    for (var i = 0; i < maxlength; ++i) {
      var count    = 0;
      var gapcount = 0;

      foreach (var word in cognate.Words) {
        if (valid word.Aligned) {
          ++count;
          if (word.Padded[i] == IPA.Segments.GapSegment)
            ++gapcount;
        }
      }
      System.Assert(gapcount < count, "Column with all gaps", cognate.Cognate);
    }

    TotalLength += maxlength;
  }

  ShowWord(SegmentClass segment) = Block{
    Paragraph {
      SpaceBefore: 10 pts;
      TextHeight: 14;
      BorderB: 1;
      "Words containing \"{0}\""(segment.Ipa);
    };
    Paragraph {
      Separator: Space;
      foreach (var cognate in UsedCognates) {
        foreach (var word in cognate.Words) {
          if (word.Segments.FindAny(segment))
            word.Plain;
        }
      }
    };
  };

  GetConcept(concept) = UsedCognates.FindFirst(c => c.Concept == concept);

  CountTransitions {
    var t = Math.MatrixInit(0, UniqueSegments.Length, UniqueSegments.Length);

    foreach (var cognate in UsedCognates) {
      var length = cognate.Words.Length;
      for (var i = 0; i < length; ++i) {
        var p0 = cognate.Words[i].Padded;
        if (p0.Length == length) {
          for (var j = i+1; j < length; ++j) {
            var p1 = cognate.Words[j].Padded;
            if (p1.Length == length) {
              for (var index = 0; index < cognate.MaxLength; ++index) {
                var s0 = p0[index];
                var s1 = p1[index];
                if (not s0.Punctuation and not s1.Punctuation and s0.Index != s1.Index) {
                  var v = t.GetValue(s0.Index, s1.Index);
                  t.SetValue(s0.Index, s1.Index, v + 1);

                  v = t.GetValue(s1.Index, s0.Index);
                  t.SetValue(s1.Index, s0.Index, v + 1);
                }
              }
            }
          }
        }
      }
    }
    return t;
  }

  void GetFrequencies {
    TransitionCount = CountTransitions;

    var set = new DictionaryClass(1024);
    foreach (var sd in SegmentFrequencyData)
      set.Add(sd, sd.Text);

    var sum = 0.0;
    foreach (var s in UniqueSegments) {
      if (not s.Punctuation) {
        var f = set.FindKey(s.Ipa);
        if (valid f)
          s.Frequency = f.Frequency;
        sum += s.Frequency;
      }
    }
    if (sum > 0) {
      sum = 1.0 / sum;

      foreach (var s in UniqueSegments) {
        s.NormalFrequency = s.Frequency * sum * 100.0;
        s.UsedFrequency   = s.UsedCount / SegmentCount * 100.0;
      }
    }
  }

  AlphaOrder(SegmentClass x, SegmentClass y) {
    var cl = x.Ipa.Length.Compare(y.Ipa.Length);
    if (cl == 0)
      cl = -x.Ipa.Compare(y.Ipa);
    return cl;
  }

  SegmentCell(SegmentClass segment) = Cell {
    Edge: 0.25 pts {Color: Colors.LightGray};
    Padding: 2 pts;
    segment.Display(segment.GlobalVariablePath, 16 pts)
  };

  SegmentTable = Block {
    var c = DocMetrics.SegmentColumns;

    Style.TitleBar {Lang.IPAListing};
    Table {
      Columns: [DocMetrics.PageContent.Width / c] * c;
      foreach (var s in (SortedSegments / c)) {
        Row {
          SegmentCell(each s);
        }
      }
    };
    Style.TableNotes;
  };

  ShowFilterSegments(FilterClass filter, align) = Frame {
    Width: 2 inches;
    Paragraph {
      ParAlignment: align;

      TextHeight: 18 pts;
      var segments = PartitionRule.GetSegments(filter);
      if (segments.Length > 0) {
        Separator: Space;
        (each segments).ShowSegment;
      }
    }
  };

  ShowLanguageDetails = Block {
    foreach (var taxon in Taxa) {
      var language = taxon.Language;
      Style.Header2 {
        language.Name;
      };
      Block {
        Paragraph {
          ParAlignment: ParAlignments.Center;
          if (valid language.MapImage)
            language.ShowMap(Size(5 inches, 3 inches));
        };
        language.Description;
        language.Details;
      }
    }
  };

  ShowLanguages = Block {
    var rows      = 2;
    var cols      = (Taxa.Length + 1) div rows;
    var taxagroup = Taxa / cols;
    var h         = 14 pts;
    var space     = 5 pts;
    var size      = Size(DocMetrics.SlideContent.Width / cols - space, DocMetrics.SlideContent.Height / rows - space);

    foreach (var group in taxagroup) {
      HBox {
        PaddingT: space;
        VAlign: VAligns.Top;

        foreach (var taxon in group) {
          VBox {
            MarginR: space;
            Size: size;
            HAlign: HAligns.Center;

            Paragraph {
              TextHeight: h;
              Bold;
              taxon.Language;
            };

            HBox {
              VAlign: VAligns.Center;

              var s = Size(size.Width, size.Height - h);
              Size: s;
              Corner: 20 pts;
              BorderStroke: 1 pts {Color: 90%};
              BorderClip: true;

              Span {
                Popup: taxon.Language;
                taxon.Language.ShowMap(s);
              }
            };
          }
        }
      }
    }
  };

  void InitSource {
    CreateFolder(OutFolder);
    if (not CharacterRule.Numbers) {
      IO.Write(CharacterFile(1), OutFolder CharacterName);
      IO.Write(RevBayesSource, OutFolder RevSourceName);
    }
    IO.Write(RunBatchFile, OutFolder FileName("Run") Extension("bat"), FileFormats.ANSI);
    IO.Write(ConfigFile, OutFolder FileName("config") Extensions.JSON, FileFormats.Text);
    Write(new SubmissionViewClass.GetDocument, OutFolder Folder("Nytril") FileName("Submission.docx"), FileFormats.Word);

    var p = new RevProcessClass(EXEName, OutFolder RevSourceName) {
/*      CacheName: "RevBayes";
      CacheInput: [
        OutFolder CharacterName,
        OutFolder RevSourceName,
      ];
      CacheOutput: [
        OutFolder GammaTrees,
        OutFolder GammaConsensus,
        OutFolder GammaMAP,
        OutFolder GammaMCC,
        OutFolder GammaLog,
      ];
*/
      Directory: OutFolder;
    };

//    var results = p.Run;
//    if (results.ExitCode != 0)
//      System.Assert(false, results.StandardOutput, p);
  }

  ShowLanguageTrees = Block {
    Style.ShowTree("Commonly Accepted Romance Tree", Lang.Years, GetTreeNodes(LanguageBranches.Romance));
    Style.ShowTree("Priors", Lang.Years, GetTreeNodes(LanguageBranches.Experiment));
//    ReadTree("MAP", OutFolder GammaMAP);
    ReadTree("Consensus", OutFolder ConsensusTree);
  };

  ShowStats = Block {
    var schema = new LogSchemaClass();
    var view   = schema.ReadTextFile(OutFolder GammaLog, true, DB.ValueTypes.Double);
    schema.GetHistogram(view, "alpha");

    schema.LineChart(view, "Prior");
    schema.LineChart(view, "Likelihood");
    schema.LineChart(view, "Posterior");
    schema.LineChart(view, "Tree Length", "TL");

//    schema.LineChart(view, null, each "bl[{0}]"(each 1..Concepts*2));
//    schema.LineChart(view, null, each "site_rates[{0}]"(each 1..Concepts));
  };

  RunBatchFile = TextBlock {
    Span {
      "\"../../revbayes/rb.exe\" \"";
      OutFolder RevSourceName;
      "\"";
    }
  };

  CompareSegments(SegmentClass s1, SegmentClass s2) = s1.UsedCount.Compare(s2.UsedCount);

  FrequencyChart(SizeClass size) = Chart {
    TextHeight: 11 pts;

    var sorted = UniqueSegments.Sort(true, ref CompareSegments);
    Style.SansSerif;
    Size: size;
    Type: ChartTypes.Column;
    Legend: ChartLegend {Placement: Placements.Bottom};
    ValueLabel: "Frequency %" {
      Transform: Rotate(90 degrees);
      TransformFit: true;
    };
    XAxis: ChartAxis {
      TextHeight: 0.6 * size.Width / sorted.Length;
      (each sorted).ShowSegment;
    };
    ValueAxis: ChartAxis;
    ChartSeries {
      Label: "All Languages";
      (each sorted).NormalFrequency;
    };
    ChartSeries {
      Label: "Experiment";
      (each sorted).UsedFrequency;
    };
  };

  AddTree = TextBlock {
    Span {
      Variable("Tree");
      Quote;
      Newick(GetTreeNodes(LanguageBranches.Experiment));
      ";"; Quote; ",";
    };
  };

  AddScope = TextBlock {
    IndentSpace: 2;
    Begin: "{";
    End: "}";
  };

  AddWord(WordClass word, last) = Span {
    "  {";
    Variable("Taxon");
    ShowString(word.Language.GlobalVariableName);
    CommaSpace;
    Variable("Segments");
    "[";
    Span {
      Separator: CommaSpace;
      (each word.Padded).CharacterIndex;
    };
    Span {
      "]}";
      if (not last)
         ",";
    };
  };

  AddCognate(CognateClass cognate, last) = TextBlock {
    Span {
      "{";
      Variable("Name");
      ShowString(cognate.Title);
      CommaSpace;
      Variable("Data"); "[";
    };

    TextBlock {
      var good = cognate.Words.FindSlice(w => valid w.Aligned);
      var lg   = good.Length-1;
      foreach (var word in good)
        AddWord(word, EachIndex == lg);
    };

    Span {
      "]}";
      if (not last)
        Comma;
    };
  };

  ConfigFile = AddScope {
    Style.MonoFamily;
    TextHeight: 9 pts;

    AddTree;
    TextBlock {
      Span {Variable("NumberOfStates"); UniqueCharacters; CommaSpace};

      Span {Variable("McmcSettings"); "{"};
        Span {Variable("FileOutput"); ShowString("/Users/johnh/Desktop/Indelly/out/test_custom"); Comma};
        Span {Variable("OnlyCompleteWords"); ShowString("No"); Comma};
        Span {Variable("Model"); ShowString("Custom"); Comma};
        Span {Variable("CalcMarginal"); ShowString("No"); Comma};
        Span {Variable("UseEigenSystem"); ShowString("No"); Comma};
        Span {Variable("NumCycles"); 1000000; Comma};
        Span {Variable("PrintFreq"); 10; Comma};
        Span {Variable("SampleFreq"); 100; Comma};
        Span {Variable("TreeLengthPriorVal"); 0.15};
      "},";
    };

    ArraySpan("Taxa") {
      Separator: CommaSpace;
      ShowString(each (each Taxa).Variable);
    };

    ArraySpan("PriorFrequencies") {
      Span {
        TextDigits: 6;
        Separator: Comma;
        (each UniqueSegments).NormalFrequency;
      };
    };

    ArraySpan("PartitionSets") {
      Span {
        Separator: Comma;
        foreach (var partition in PartitionRule.Partitions) {
          Span {
            "{";
            Variable("Name");
            ShowString(partition.Filter.Name);
            CommaSpace;
            Variable("Set");
            "[";
            Span {
              Separator: CommaSpace;
              (each partition.Segments).CharacterIndex;
            };
            "]}";
          }
        }
      };
    };

    Span {
      Variable("Words"); "[";
    };
    TextBlock {
      var last = UsedCognates.Length-1;
      foreach (var cognate in UsedCognates)
        AddCognate(cognate, EachIndex == last);
    };
    "]";
  };

  RevBayesSource = TextBlock {
    Style.MonoFamily;
    BlockComment("RevBayes Source File for Linguistomics Project");

    "clear()";
//    "setwd({0})"(ShowString(folder));
    "path = " ShowString(OutFolder Folder("/"));
    "gammapath = {0}"(PathPlus(GammaTrees));


    LineComment("Read in discrete character data");
    "data = readDiscreteCharacterData({0})"(PathPlus(CharacterName));

    LineComment("Get some useful variables from the data. We need these later on");
    "num_taxa <- data.ntaxa()";

    LineComment("Number of branches in an rooted tree");
    "num_branches <- 2 * num_taxa - 2";

    "taxa <- data.taxa()";

    LineComment("Create helper variables");
    "moves    = VectorMoves()";
    "monitors = VectorMonitors()";

    BlockComment("Tree Model");
    LineComment("Outgroup is a clade consisting of one language");
    "out_group = clade({0})"(ShowString(Languages.Latin));

    LineComment("Prior distribution on the tree topology");
    "topology ~ dnUniformTopology(taxa, outgroup=out_group, rooted=TRUE)";

    LineComment("These are moves that change the tree topology");
    "moves.append(mvNNI(topology, weight=num_taxa/2.0))";
    "moves.append(mvSPR(topology, weight=num_taxa/10.0))";

    LineComment("Branch length prior");

    "for (i in 1:num_branches) {";
    "  bl[i] ~ dnExponential(10.0)";
    "  moves.append(mvScale(bl[i]))";
    "}";
    Empty;
    "TL  := sum(bl)";
    Empty;
    "psi := treeAssembly(topology, bl)";
    Empty;

    BlockComment("Substitution Model");
    LineComment("This is the number of unique characters from the segment filters");
    "unique_chars = {0}"(UniqueCharacters);

    switch (Model) {
      case Models.JC:
        LineComment("Jukes-Cantor model");
        "Q <- fnJC(unique_chars)";
        break;

      case Models.MK:
        LineComment("Mk model");
        LineComment("I'm guessing completely with this number");
        "rate_pr <- 10.0";
        Empty;
        "rate_parameter ~ dnExponential(rate_pr)";
        Empty;
        Empty;
        "moves.append(mvScale(rate_parameter, weight=2))";
        Empty;
        "for (i in 1:unique_chars) {";
        "  for (j in 1:unique_chars) {";
        "    m[i][j] := rate_parameter";
        "  }";
        "}";
        Empty;
        "Q := fnFreeK(m, rescale=TRUE)";
        break;
    }

    BlockComment("Gamma model for among-site variation");

    "alpha ~ dnUniform(0, 10.0)";
    "moves.append(mvScale(alpha, weight=1))";

    "site_rates := fnDiscretizeGamma(alpha, alpha, 4)";

    BlockComment("PhyloCTMC Model");
    "seq ~ dnPhyloCTMC(tree=psi, Q=Q, type={0}, siteRates=site_rates)"(ShowString("Standard"));
    "seq.clamp(data)";

    BlockComment("Analysis");

    LineComment("You can use any node as the argument of model()");
    "mymodel = model(psi)";
    "n_gen   = {0}"(Math.Min([100, Math.Max([10, Info.Generations div 1000])]));

    LineComment("This prints monitors to the screen");
    Span {
      "monitors.append(mnScreen(TL, ";
      if (Model == Models.MK)
        "rate_parameter, ";
      "printgen=n_gen))";
    };

    LineComment("This monitors the trees and puts them in a file");
    "monitors.append(mnFile(psi, filename=gammapath, printgen=n_gen))";

    LineComment("Model monitor");
    "monitors.append(mnModel(filename={0}, printgen=n_gen))"(PathPlus(GammaLog));

    "mymcmc = mcmc(mymodel, moves, monitors, nruns=1, combine={0})"(ShowString("mixed"));


//   "mymcmc.burnin(generations={0}, tuningInterval=200)"(Info.Generations);
    "mymcmc.run(generations={0})"(Info.Generations);

    LineComment("Summarizes the MCMC runs");
    "mymcmc.operatorSummary()";

    BlockComment("Post processing");
    "treetrace      = readTreeTrace(gammapath, outgroup=out_group)";
    "map_tree       = mapTree(treetrace, {0})"(PathPlus(GammaMAP));
    "mcc_tree       = mccTree(treetrace, {0})"(PathPlus(ConsensusTree));
    "consensus_tree = consensusTree(treetrace, {0})"(PathPlus(GammaConsensus));

    LineComment("Exit the program");
    "q()";
  };

  CharacterFile(paper) = NexusFile {
    var maxlength = MaxNameLength;
    var ntax      = Taxa.Length;

    TabStops: [4 inches];

    Scope("taxa") {
      AddLine("dimensions") {
        AddValue("ntax", ntax);
      };
      AddLine("taxlabels") {
        AddTaxon(each Taxa);
      };
    };

    Scope("characters") {
      AddLine("dimensions") {
        AddValue("ntax", ntax);
        AddValue("nchar", TotalLength);
      };
      AddLine("format") {
        AddValue("datatype", "STANDARD");
        AddValue("interleave", "yes");
        AddValue("respectcase");
        AddValue("gap", IPA.Segments.GapSegment.Ipa);
        AddValue("missing", IPA.Segments.MissingSegment.Ipa);
        AddValue("symbols", Span {Quote; CharacterList[0..<Math.Min([UniqueCharacters, Rev.CharacterList.Length])]; Quote});
      };

      Empty;
      Keyword("matrix");

      foreach (var cognate in UsedCognates) {
        if (EachIndex > 0)
          Empty;

        Comment(cognate.Name);
        WriteTaxa(cognate, paper, maxlength);
      }
      EndMarker;
    };
  };

  MaxNameLength = Math.Max((each ((each Taxa).Variable)).Length) + 1;

  WriteTaxa(CognateClass cognate, paper, maxlength) = TextBlock {
    foreach (var taxon in Taxa) {
      var words = cognate.Words[taxon.Index];
      Span {
        taxon.Variable;
        Space * (maxlength - taxon.Variable.Length);
        foreach (var segment in words.Padded)
          segment.ShowCharacter;

        switch (paper) {
          case 0:
            break;

          case 1:
            break;

          case 2:
            Span {
              CommentFormat;
              Style.IPAFamily;
              Tab;
              foreach (var segment in words.Padded)
                segment.ShowBlock;
            };
            break;
        }
      };
    }
  };

  ShowWordsForEachSegment = Block {
    foreach (var segment in SortedSegments) {
      Paragraph {
        TabStops: [0.5 inches, DocMetrics.PageContent.Width {Type: TabTypes.Right}];
        KeepWithNext: true;
        TextHeight: 16 pts;
        ParBackground: 90%;

        segment.ShowSegment;
        Tab;
        segment.ShowCodePoint
        Tab;
        segment.ShowCharacter;
      };

      Paragraph {
        ParAlignment: ParAlignments.Justify;
        Style.IPAFamily;
        SpaceAfter: 10 pts;
        Span {
          Separator: Space*2;
          foreach (var cognate in UsedCognates) {
            foreach (var word in cognate.Words) {
              if (word.Segments.FindAny(segment)) {
                Span {
                  Popup: word;
                  word.Plain;
                }
              }
            }
          }
        };
      };
    }
  };
}
}
//======================================================================

